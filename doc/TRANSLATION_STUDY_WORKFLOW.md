# Translation + Study Workflow - Faceded Algo Deep Dive

**Date**: October 22, 2025  
**Goal**: Mix translation work with algorithmic learning through facades  
**Pattern**: Build â†’ Learn â†’ Optimize â†’ Document

---

## ðŸŽ¯ The "Faceded Algo" Approach

```
NOT: "Translate the facade, move on"
YES: "Translate the facade, THEN face the algorithm"

For each algorithm:
â”œâ”€ Translate facade (structural work)
â”œâ”€ Study the algorithm spec (understand logic)
â”œâ”€ Test with real graphs (verify correctness)
â”œâ”€ Analyze performance (optimize hot paths)
â””â”€ Document findings (what did we learn?)
```

---

## ðŸ“š Why This Works

**Building facades FORCES understanding:**

```
Shallow Approach:
â”œâ”€ Read algorithm paper
â”œâ”€ Look at Java implementation
â””â”€ "Yeah, I get it"
(You don't - you just copied)

Faceded Deep Dive:
â”œâ”€ Read algorithm paper
â”œâ”€ Look at Java implementation
â”œâ”€ Build the facade (choose what to expose!)
â”œâ”€ Write tests (verify it works)
â”œâ”€ Profile it (find bottlenecks)
â”œâ”€ Document findings (explain to future self)
â””â”€ NOW you understand it
```

The facade forces decisions:
- What configuration matters?
- What results matter?
- What edge cases exist?
- How does performance scale?

---

## ðŸ”„ Today's Translation + Study Cycle

### **For EACH Algorithm:**

```
HOUR 1: TRANSLATION
â”œâ”€ Create facade file
â”œâ”€ Choose configuration parameters
â”œâ”€ Implement stream/stats/mutate modes
â””â”€ Write skeleton tests

HOUR 2: STUDY
â”œâ”€ Read algorithm spec deeply
â”œâ”€ Trace through the logic
â”œâ”€ Understand the parameters
â””â”€ Verify your facade choices were right

HOUR 3: VERIFICATION
â”œâ”€ Run tests on real graphs
â”œâ”€ Check edge cases
â”œâ”€ Profile performance
â””â”€ Document 3 key learnings
```

**Total per algorithm: ~2.5-3 hours**

---

## ðŸš€ Today's Translation Target: 3 Centrality Algorithms

Start with centrality because:
- âœ… Simplest patterns (most are just node scores)
- âœ… Easy to understand (global vs local)
- âœ… Easy to test (run, check results make sense)
- âœ… Quick to translate (straightforward facades)

### **Algorithm 1: DegreeCentrality** (30 min)

**TRANSLATION:**
```rust
// Simplest possible - no config!
pub fn stream(self) -> Result<impl Iterator<Item = (u64, f64)>>
pub fn stats(self) -> Result<DegreeCentralityStats> {
    // min, max, mean, median degree
}
```

**STUDY:**
```
Ask yourself:
â”œâ”€ Why do we care about degree?
â”œâ”€ What's a high degree node? Low?
â”œâ”€ Edge cases: isolated nodes? Dense clusters?
â””â”€ Performance: O(V+E) always, or depends on graph shape?

Read the spec:
â”œâ”€ Is it in-degree, out-degree, or both?
â”œâ”€ How does it handle isolated nodes?
â”œâ”€ What about self-loops?

Test on real graphs:
â”œâ”€ Small star graph (hub topology)
â”œâ”€ Complete graph (all same degree)
â”œâ”€ Bipartite (two groups)
```

**FINDINGS TO DOCUMENT:**
- "Degree reveals structural roles"
- "Isolated nodes = degree 0 (edge case)"
- "Performance: linear in graph size"

---

### **Algorithm 2: PageRank** (1.5 hours)

**TRANSLATION:**
```rust
pub struct PageRankBuilder {
    iterations: u32,
    tolerance: f64,
    damping_factor: f64,
}

pub fn stream(self) -> Result<impl Iterator<Item = (u64, f64)>>
pub fn stats(self) -> Result<PageRankStats> {
    // min, max, mean, converged, iterations_run
}
```

**STUDY:**
```
Ask yourself:
â”œâ”€ Why does damping factor matter?
â”œâ”€ What's the "random surfer" model?
â”œâ”€ How does iteration affect accuracy?
â”œâ”€ When does it converge?

Read the spec:
â”œâ”€ How is convergence detected?
â”œâ”€ What's the default damping factor? (0.85)
â”œâ”€ How many iterations needed typically?

Test on real graphs:
â”œâ”€ Vary iterations: 10, 20, 50, 100
â”œâ”€ Vary damping: 0.5, 0.85, 0.99
â”œâ”€ Check convergence on different graph shapes
â”œâ”€ Compare with DegreeCentrality results (similar? different?)
```

**FINDINGS TO DOCUMENT:**
- "Damping 0.85 is sweet spot (tradition from Google)"
- "Converges in 15-20 iterations typically"
- "High-degree nodes don't always get high PR (importance â‰  degree)"

---

### **Algorithm 3: Betweenness Centrality** (1.5 hours)

**TRANSLATION:**
```rust
pub struct BetweennessBuilder {
    // No config needed! (or maybe sampling for large graphs)
}

pub fn stream(self) -> Result<impl Iterator<Item = (u64, f64)>>
pub fn stats(self) -> Result<BetweennessStats> {
    // min, max, mean scores
    // computational_time_ms (important - O(V*E)!)
}
```

**STUDY:**
```
Ask yourself:
â”œâ”€ What does "betweenness" mean intuitively?
â”œâ”€ Which nodes are bridges in the network?
â”œâ”€ Why does it take longer than PageRank?
â”œâ”€ Edge case: disconnected nodes?

Read the spec:
â”œâ”€ Is it Brandes' algorithm?
â”œâ”€ Normalized or absolute scores?
â”œâ”€ How are ties broken?

Test on real graphs:
â”œâ”€ Bridge graphs (obvious bridges)
â”œâ”€ Star graphs (center has high betweenness)
â”œâ”€ Cycles (all equal? no!)
â”œâ”€ Time it on smallâ†’mediumâ†’large graphs
```

**FINDINGS TO DOCUMENT:**
- "Betweenness = number of shortest paths through a node"
- "Much slower than PageRank (O(V*E) vs O(V+E))"
- "Bridges have very high betweenness"

---

## ðŸ“Š Translation + Study Outputs

For EACH algorithm, you produce:

```
1. gds/src/procedures/facades/centrality/[algorithm].rs
   â””â”€ Complete facade with all 4 modes

2. gds/src/procedures/facades/centrality/tests/[algorithm]_tests.rs
   â””â”€ Comprehensive tests covering edge cases

3. doc/algorithm_study/[algorithm]_analysis.md
   â””â”€ What you learned:
      â”œâ”€ Algorithm essence (1 paragraph)
      â”œâ”€ Key parameters and their effects
      â”œâ”€ Performance characteristics
      â”œâ”€ Typical use cases
      â”œâ”€ Edge cases discovered
      â””â”€ Comparison with similar algorithms
```

---

## ðŸŽ“ Daily Cycle Suggestions

### **Morning (2-3 hours): Translation**
- Write 1-2 facades
- Tests pass locally
- Code compiles

### **Afternoon (2-3 hours): Study + Optimization**
- Run facades on diverse graphs
- Measure performance
- Understand the algorithms deeply
- Document findings

### **Evening (optional): Refine**
- Optimize hot paths discovered
- Update documentation
- Plan tomorrow's algorithms

---

## ðŸ”‘ The Learning Pattern

```
Day 1:  DegreeCentrality, PageRank, Betweenness
        â””â”€ You learn: Local vs global importance

Day 2:  Closeness, Harmonic, HarmonicCentrality
        â””â”€ You learn: Different notions of importance

Day 3:  HITS
        â””â”€ You learn: Bidirectional importance (hubs vs authorities)

After 3 days:
â”œâ”€ You've translated 6 facades
â”œâ”€ You understand centrality deeply
â”œâ”€ You see patterns (iterations, convergence, normalization)
â””â”€ Pattern extends to other domains
```

---

## ðŸŽ¯ This Week's Translation Goal

```
Week 1: Centrality (6 facades)
â”œâ”€ Mon: DegreeCentrality, PageRank, Betweenness
â”œâ”€ Tue: Closeness, Harmonic, HITS
â””â”€ ~20-25 lines of facade code per algorithm

Week 2: Community (5 facades)
â”œâ”€ Mon-Tue: Louvain, LabelPropagation, WCC
â”œâ”€ Wed: LocalClusteringCoefficient, TriangleCount
â””â”€ Different patterns (node IDs vs statistics)

Week 3: Path Finding (subset)
â”œâ”€ Dijkstra, BFS, DFS, A*
â””â”€ Learn: Single-source vs all-pairs, weighted vs unweighted
```

---

## ðŸ’¡ Why "Translate + Study" Works Better

```
SPEED:    âœ… Translation is mechanical (copy structure)
LEARNING: âœ… Study phase deepens understanding
QUALITY:  âœ… Tests ensure correctness from day 1
PATTERNS: âœ… See what changes (config), what's constant (results)
DOCS:     âœ… Natural documentation from learning
```

You're not just translating algorithmsâ€”you're **learning graph science through implementation.**

That's the power of this approach.

---

## ðŸš€ Start Now

1. Create `gds/src/procedures/facades/centrality/` 
2. Start with `DegreeCentrality` (easiest, 30 min)
3. Then `PageRank` (learn iterations + convergence, 1 hour)
4. Then `Betweenness` (learn complexity, 1 hour)

After today: 3 facades, deep understanding of centrality.

Tomorrow: 3 more facades, broader understanding of what matters in graphs.

By end of week: Complete centrality domain mastery + beautiful facade layer.

**Translation + Study = Mastery.** ðŸŽ¯

Let's go. ðŸš€

